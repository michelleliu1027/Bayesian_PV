{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimisation Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from matplotlib import pyplot as plt\r\n",
    "from matplotlib.colors import LogNorm\r\n",
    "from scipy.interpolate import interp1d\r\n",
    "from scipy import interpolate\r\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\r\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\r\n",
    "from scipy import stats\r\n",
    "from scipy.stats import norm\r\n",
    "from sklearn.metrics.pairwise import euclidean_distances\r\n",
    "from scipy.spatial.distance import cdist\r\n",
    "from scipy.optimize import fsolve\r\n",
    "import math\r\n",
    "\r\n",
    "def warn(*args, **kwargs):\r\n",
    "    pass\r\n",
    "import warnings\r\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial on TiOx/SiOx\n",
    "Tempeature vs. S10_HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #import timestamp from data sheet (time:0~5000s) \r\n",
    "address = 'data/degradation.xlsx'\r\n",
    "# df = pd.read_excel(address,sheet_name = 'normal data',usecols = [0],names = None,nrows = 5000)\r\n",
    "# df_time = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data sheet at 85 C (time:0~5000s) \r\n",
    "\r\n",
    "df = pd.read_excel(address,sheet_name = 'normal data',usecols = [3],names = None,nrows = 5000)\r\n",
    "df_85 = df.values.tolist() \r\n",
    "df = pd.read_excel(address,sheet_name = 'smooth data',usecols = [3],names = None,nrows = 5000)\r\n",
    "df_85s = df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format date into numpy array format\r\n",
    "# x_normal = np.array(df_time).T\r\n",
    "y_normal = np.array(df_85).T \r\n",
    "# x_normal = x_normal.reshape((5000))\r\n",
    "y_normal = y_normal.reshape((5000))\r\n",
    "X_ = np.linspace(0,5000, 5000)\r\n",
    "x_normal = X_\r\n",
    "x_7_5000 = np.array([0,99,999,1999,2999,3999,4999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot function\r\n",
    "def plot (x_normal ,y_normal, X,X_,y_mean,Y,y_cov):\r\n",
    "    #plot function\r\n",
    "    plt.figure()\r\n",
    "    plt.plot(X_, y_mean, 'k', lw=1, zorder=4)\r\n",
    "    plt.fill_between(X_, y_mean - np.sqrt(np.diag(y_cov)),y_mean + np.sqrt(np.diag(y_cov)),alpha=0.5, color='k')\r\n",
    "    # plt.scatter(X[:, 0], Y, c='r', s=1, zorder=3)\r\n",
    "    plt.plot(x_normal, y_normal, 'c', lw=1, zorder=2)\r\n",
    "    plt.tick_params(axis='y', colors = 'white')\r\n",
    "    plt.tick_params(axis='x', colors = 'white')\r\n",
    "    plt.ylabel('Lifetime',color = 'white')\r\n",
    "    plt.xlabel('Time',color = 'white')\r\n",
    "    plt.title('Original')\r\n",
    "    plt.xlim(0,4900)\r\n",
    "    plt.ylim(0.7,0.8)\r\n",
    "    plt.tight_layout()\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preparing training set from a few data points\r\n",
    "# NUM_OF_DATA_POINTS = 100\r\n",
    "# x_loop = np.arange(0,5000,int(5000/NUM_OF_DATA_POINTS))\r\n",
    "# X = x_loop\r\n",
    "# Y = y_normal[x_loop]\r\n",
    "# X = X.reshape(x_loop.size,1)\r\n",
    "\r\n",
    "\r\n",
    "# # Kernel setting\r\n",
    "# length_scale_bounds_MAX = None\r\n",
    "# length_scale_bounds_MIN = 1e-4\r\n",
    "\r\n",
    "# for length_scale_bounds_MAX in (10,20,50,100,200,400,500,700,1000,1500,2000):\r\n",
    "#     kernel = 1.0 * RBF(length_scale=20,length_scale_bounds=(length_scale_bounds_MIN, length_scale_bounds_MAX)) + WhiteKernel(noise_level=0.0001)\r\n",
    "#     gp = GaussianProcessRegressor(kernel=kernel,alpha=0.0).fit(X, Y)\r\n",
    "#     y_mean, y_cov = gp.predict(X_[:, np.newaxis], return_cov=True)\r\n",
    "#     print('Length scale bound max =',length_scale_bounds_MAX)\r\n",
    "#     print ('Average absolute error:',\r\n",
    "#     np.format_float_scientific(np.mean(np.absolute(y_normal-y_mean)),precision=5))\r\n",
    "#     print ('Average percentage error:',\r\n",
    "#     np.format_float_positional(np.mean(np.absolute((y_normal-y_mean)/y_normal*100)),precision=4),'%')\r\n",
    "#     plot(x_normal ,y_normal, X,X_,y_mean,Y,y_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquisition_equation as ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-41bc494c36e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# Get ucb prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0macp_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mucb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;31m# X_min = np.argmin(acp_value[-1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# ucb_y_min = acp_value[-1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\OneDrive\\xietong\\Bayesian_PV\\acquisition_equation.py\u001b[0m in \u001b[0;36mucb\u001b[1;34m(X, gp, dim, delta)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;31m# return mean - np.sqrt(beta)* np.sqrt(np.diag(var))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmean\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "# Preparing training set from a range of data points\r\n",
    "# Kernel setting\r\n",
    "length_scale_bounds_MAX = 400\r\n",
    "length_scale_bounds_MIN = 1e-4\r\n",
    "\r\n",
    "for NUM_OF_DATA_POINTS in (20,30,40,50,60,80,100,120,150,200,300,500):\r\n",
    "    x_loop = np.arange(0,5000,int(5000/NUM_OF_DATA_POINTS))\r\n",
    "    X = x_normal[x_loop].reshape(x_loop.size)\r\n",
    "    Y = y_normal[x_loop]\r\n",
    "    X = X.reshape(x_loop.size,1)\r\n",
    "    \r\n",
    "    kernel = 1.0 * RBF(length_scale=20,length_scale_bounds=(length_scale_bounds_MIN, length_scale_bounds_MAX)) + WhiteKernel(noise_level=0.00000001)\r\n",
    "    gp = GaussianProcessRegressor(kernel=kernel,alpha=0.0).fit(X, Y)\r\n",
    "    y_mean, y_cov = gp.predict(X_[:, np.newaxis], return_cov=True)\r\n",
    "\r\n",
    "    # Get ucb prediction\r\n",
    "    acp_value = ae.ucb(X_, gp, 0.1, 5)\r\n",
    "    # X_min = np.argmin(acp_value[-1])\r\n",
    "    # ucb_y_min = acp_value[-1]\r\n",
    "\r\n",
    "    print('Number of data points used:', x_loop.size)\r\n",
    "    print('Length scale bound max =',length_scale_bounds_MAX)\r\n",
    "    print ('Average absolute error:',\r\n",
    "    np.format_float_scientific(np.mean(np.absolute(y_normal-y_mean)),precision=5))\r\n",
    "    print ('Average percentage error:',\r\n",
    "    np.format_float_positional(np.mean(np.absolute((y_normal-y_mean)/y_normal*100)),precision=4),'%')\r\n",
    "    \r\n",
    "    #plot function\r\n",
    "    plt.figure()\r\n",
    "    plt.plot(X_, y_mean, 'k', lw=1, zorder=4)\r\n",
    "    plt.fill_between(X_, y_mean - np.sqrt(np.diag(y_cov)),y_mean + np.sqrt(np.diag(y_cov)),alpha=0.5, color='k')\r\n",
    "    plt.plot(x_normal, y_normal, 'c', lw=1, zorder=2)\r\n",
    "    # plt.plot(x_normal,ucb_y_min,'pink',lw=1,zorder=5)\r\n",
    "    # plt.scatter(np.argmin(ucb_y_min), min(ucb_y_min), c='r', s=20, zorder=6)\r\n",
    "    plt.plot(x_normal,acp_value,'pink',lw=1,zorder=5)\r\n",
    "\r\n",
    "    plt.tick_params(axis='y', colors = 'white')\r\n",
    "    plt.tick_params(axis='x', colors = 'white')\r\n",
    "    plt.ylabel('Lifetime',color = 'white')\r\n",
    "    plt.xlabel('Time',color = 'white')\r\n",
    "    plt.title('Original')\r\n",
    "    # plt.xlim(0,4900)\r\n",
    "    # plt.ylim(0.7,0.8)\r\n",
    "    plt.tight_layout()\r\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}